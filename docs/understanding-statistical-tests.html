<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 5 Understanding Statistical Tests | Data Science for Agricultural Professionals</title>
  <meta name="description" content="Practical statistics for those involved in agronomy and related agricultural sciences." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 5 Understanding Statistical Tests | Data Science for Agricultural Professionals" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Practical statistics for those involved in agronomy and related agricultural sciences." />
  <meta name="github-repo" content="https://github.com/mharbur/ds-oct21c" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 5 Understanding Statistical Tests | Data Science for Agricultural Professionals" />
  
  <meta name="twitter:description" content="Practical statistics for those involved in agronomy and related agricultural sciences." />
  

<meta name="author" content="Marin L. Harbur" />


<meta name="date" content="2021-10-07" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="two-treatment-comparisons.html"/>
<link rel="next" href="multiple-treatment-trials.html"/>
<script src="libs/header-attrs-2.11/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.9.4.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.1.1/css/crosstalk.css" rel="stylesheet" />
<script src="libs/crosstalk-1.1.1/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-1.57.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-1.57.1/plotly-latest.min.js"></script>
<link href="libs/leaflet-1.3.1/leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-1.3.1/leaflet.js"></script>
<link href="libs/leafletfix-1.0.0/leafletfix.css" rel="stylesheet" />
<script src="libs/proj4-2.6.2/proj4.min.js"></script>
<script src="libs/Proj4Leaflet-1.0.1/proj4leaflet.js"></script>
<link href="libs/rstudio_leaflet-1.3.1/rstudio_leaflet.css" rel="stylesheet" />
<script src="libs/leaflet-binding-2.0.4.1/leaflet.js"></script>
<script src="libs/leaflet-providers-1.9.0/leaflet-providers_1.9.0.js"></script>
<script src="libs/leaflet-providers-plugin-2.0.4.1/leaflet-providers-plugin.js"></script>
<script src="libs/stars_1f4d28-1/data_stars_starsf098bd.txt"></script>
<script src="libs/joda-0.0.1/joda.js"></script>
<script src="libs/joda-0.0.1/addImageQuery-bindings.js"></script>
<script src="libs/stars_f4bdc0-1/data_stars_starsd4cae3.txt"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Data Science for Agricultural Professionals</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#welcome"><i class="fa fa-check"></i>Welcome</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#r-language"><i class="fa fa-check"></i>R-language</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="population-statistics.html"><a href="population-statistics.html"><i class="fa fa-check"></i><b>1</b> Population Statistics</a>
<ul>
<li class="chapter" data-level="1.1" data-path="population-statistics.html"><a href="population-statistics.html#populations"><i class="fa fa-check"></i><b>1.1</b> Populations</a></li>
<li class="chapter" data-level="1.2" data-path="population-statistics.html"><a href="population-statistics.html#case-study-yield-map"><i class="fa fa-check"></i><b>1.2</b> Case Study: Yield Map</a></li>
<li class="chapter" data-level="1.3" data-path="population-statistics.html"><a href="population-statistics.html#distributions"><i class="fa fa-check"></i><b>1.3</b> Distributions</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="population-statistics.html"><a href="population-statistics.html#histograms"><i class="fa fa-check"></i><b>1.3.1</b> Histograms</a></li>
<li class="chapter" data-level="1.3.2" data-path="population-statistics.html"><a href="population-statistics.html#percentiles"><i class="fa fa-check"></i><b>1.3.2</b> Percentiles</a></li>
<li class="chapter" data-level="1.3.3" data-path="population-statistics.html"><a href="population-statistics.html#normal-distribution-model"><i class="fa fa-check"></i><b>1.3.3</b> Normal Distribution Model</a></li>
<li class="chapter" data-level="1.3.4" data-path="population-statistics.html"><a href="population-statistics.html#measures-of-center"><i class="fa fa-check"></i><b>1.3.4</b> Measures of Center</a></li>
<li class="chapter" data-level="1.3.5" data-path="population-statistics.html"><a href="population-statistics.html#measures-of-dispersion"><i class="fa fa-check"></i><b>1.3.5</b> Measures of Dispersion</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="distributions-and-probability.html"><a href="distributions-and-probability.html"><i class="fa fa-check"></i><b>2</b> Distributions and Probability</a>
<ul>
<li class="chapter" data-level="2.1" data-path="distributions-and-probability.html"><a href="distributions-and-probability.html#case-study"><i class="fa fa-check"></i><b>2.1</b> Case Study</a></li>
<li class="chapter" data-level="2.2" data-path="distributions-and-probability.html"><a href="distributions-and-probability.html#the-normal-distribution-model"><i class="fa fa-check"></i><b>2.2</b> The Normal Distribution Model</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="distributions-and-probability.html"><a href="distributions-and-probability.html#the-bell-curve"><i class="fa fa-check"></i><b>2.2.1</b> The Bell Curve</a></li>
<li class="chapter" data-level="2.2.2" data-path="distributions-and-probability.html"><a href="distributions-and-probability.html#distribution-and-probability"><i class="fa fa-check"></i><b>2.2.2</b> Distribution and Probability</a></li>
<li class="chapter" data-level="2.2.3" data-path="distributions-and-probability.html"><a href="distributions-and-probability.html#probability-and-the-normal-distribution-curve"><i class="fa fa-check"></i><b>2.2.3</b> Probability and the Normal Distribution Curve</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="distributions-and-probability.html"><a href="distributions-and-probability.html#the-z-distribution"><i class="fa fa-check"></i><b>2.3</b> The Z-Distribution</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="distributions-and-probability.html"><a href="distributions-and-probability.html#important-numbers-95-and-5"><i class="fa fa-check"></i><b>2.3.1</b> Important Numbers: 95% and 5%</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="sample-statistics.html"><a href="sample-statistics.html"><i class="fa fa-check"></i><b>3</b> Sample Statistics</a>
<ul>
<li class="chapter" data-level="3.1" data-path="sample-statistics.html"><a href="sample-statistics.html#samples"><i class="fa fa-check"></i><b>3.1</b> Samples</a></li>
<li class="chapter" data-level="3.2" data-path="sample-statistics.html"><a href="sample-statistics.html#case-study-1"><i class="fa fa-check"></i><b>3.2</b> Case Study</a></li>
<li class="chapter" data-level="3.3" data-path="sample-statistics.html"><a href="sample-statistics.html#distribution-of-sample-means"><i class="fa fa-check"></i><b>3.3</b> Distribution of Sample Means</a></li>
<li class="chapter" data-level="3.4" data-path="sample-statistics.html"><a href="sample-statistics.html#central-limit-theorem"><i class="fa fa-check"></i><b>3.4</b> Central Limit Theorem</a></li>
<li class="chapter" data-level="3.5" data-path="sample-statistics.html"><a href="sample-statistics.html#standard-error"><i class="fa fa-check"></i><b>3.5</b> Standard Error</a></li>
<li class="chapter" data-level="3.6" data-path="sample-statistics.html"><a href="sample-statistics.html#degrees-of-freedom"><i class="fa fa-check"></i><b>3.6</b> Degrees of Freedom</a></li>
<li class="chapter" data-level="3.7" data-path="sample-statistics.html"><a href="sample-statistics.html#the-t-distribution"><i class="fa fa-check"></i><b>3.7</b> The t-Distribution</a></li>
<li class="chapter" data-level="3.8" data-path="sample-statistics.html"><a href="sample-statistics.html#confidence-interval"><i class="fa fa-check"></i><b>3.8</b> Confidence Interval</a></li>
<li class="chapter" data-level="3.9" data-path="sample-statistics.html"><a href="sample-statistics.html#confidence-interval-and-probability"><i class="fa fa-check"></i><b>3.9</b> Confidence Interval and Probability</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="two-treatment-comparisons.html"><a href="two-treatment-comparisons.html"><i class="fa fa-check"></i><b>4</b> Two-Treatment Comparisons</a>
<ul>
<li class="chapter" data-level="4.1" data-path="two-treatment-comparisons.html"><a href="two-treatment-comparisons.html#side-by-side-trials"><i class="fa fa-check"></i><b>4.1</b> Side-by-Side Trials</a></li>
<li class="chapter" data-level="4.2" data-path="two-treatment-comparisons.html"><a href="two-treatment-comparisons.html#blocked-design"><i class="fa fa-check"></i><b>4.2</b> Blocked Design</a></li>
<li class="chapter" data-level="4.3" data-path="two-treatment-comparisons.html"><a href="two-treatment-comparisons.html#case-study-2"><i class="fa fa-check"></i><b>4.3</b> Case Study</a></li>
<li class="chapter" data-level="4.4" data-path="two-treatment-comparisons.html"><a href="two-treatment-comparisons.html#confidence-interval-1"><i class="fa fa-check"></i><b>4.4</b> Confidence Interval</a></li>
<li class="chapter" data-level="4.5" data-path="two-treatment-comparisons.html"><a href="two-treatment-comparisons.html#t-test"><i class="fa fa-check"></i><b>4.5</b> T-Test</a></li>
<li class="chapter" data-level="4.6" data-path="two-treatment-comparisons.html"><a href="two-treatment-comparisons.html#conclusion"><i class="fa fa-check"></i><b>4.6</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="understanding-statistical-tests.html"><a href="understanding-statistical-tests.html"><i class="fa fa-check"></i><b>5</b> Understanding Statistical Tests</a>
<ul>
<li class="chapter" data-level="5.1" data-path="understanding-statistical-tests.html"><a href="understanding-statistical-tests.html#research-question"><i class="fa fa-check"></i><b>5.1</b> Research Question</a></li>
<li class="chapter" data-level="5.2" data-path="understanding-statistical-tests.html"><a href="understanding-statistical-tests.html#the-model"><i class="fa fa-check"></i><b>5.2</b> The Model</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="understanding-statistical-tests.html"><a href="understanding-statistical-tests.html#treatment-effect"><i class="fa fa-check"></i><b>5.2.1</b> Treatment Effect</a></li>
<li class="chapter" data-level="5.2.2" data-path="understanding-statistical-tests.html"><a href="understanding-statistical-tests.html#error-effect"><i class="fa fa-check"></i><b>5.2.2</b> Error Effect</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="understanding-statistical-tests.html"><a href="understanding-statistical-tests.html#hypotheses"><i class="fa fa-check"></i><b>5.3</b> Hypotheses</a></li>
<li class="chapter" data-level="5.4" data-path="understanding-statistical-tests.html"><a href="understanding-statistical-tests.html#p-value"><i class="fa fa-check"></i><b>5.4</b> P-Value</a></li>
<li class="chapter" data-level="5.5" data-path="understanding-statistical-tests.html"><a href="understanding-statistical-tests.html#the-p-value-and-errors"><i class="fa fa-check"></i><b>5.5</b> The P-Value and Errors</a></li>
<li class="chapter" data-level="5.6" data-path="understanding-statistical-tests.html"><a href="understanding-statistical-tests.html#one-sided-vs-two-sided-hypotheses"><i class="fa fa-check"></i><b>5.6</b> One-Sided vs Two-Sided Hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="multiple-treatment-trials.html"><a href="multiple-treatment-trials.html"><i class="fa fa-check"></i><b>6</b> Multiple Treatment Trials</a>
<ul>
<li class="chapter" data-level="6.1" data-path="multiple-treatment-trials.html"><a href="multiple-treatment-trials.html#case-study-3"><i class="fa fa-check"></i><b>6.1</b> Case Study</a></li>
<li class="chapter" data-level="6.2" data-path="multiple-treatment-trials.html"><a href="multiple-treatment-trials.html#the-linear-additive-model"><i class="fa fa-check"></i><b>6.2</b> The Linear Additive Model</a></li>
<li class="chapter" data-level="6.3" data-path="multiple-treatment-trials.html"><a href="multiple-treatment-trials.html#analysis-of-variance"><i class="fa fa-check"></i><b>6.3</b> Analysis of Variance</a></li>
<li class="chapter" data-level="6.4" data-path="multiple-treatment-trials.html"><a href="multiple-treatment-trials.html#the-f-statistic"><i class="fa fa-check"></i><b>6.4</b> The F statistic</a></li>
<li class="chapter" data-level="6.5" data-path="multiple-treatment-trials.html"><a href="multiple-treatment-trials.html#the-anova-table"><i class="fa fa-check"></i><b>6.5</b> The ANOVA Table</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="multiple-treatment-trials.html"><a href="multiple-treatment-trials.html#source-of-variation"><i class="fa fa-check"></i><b>6.5.1</b> Source of Variation</a></li>
<li class="chapter" data-level="6.5.2" data-path="multiple-treatment-trials.html"><a href="multiple-treatment-trials.html#sum-of-squares-1"><i class="fa fa-check"></i><b>6.5.2</b> Sum of Squares</a></li>
<li class="chapter" data-level="6.5.3" data-path="multiple-treatment-trials.html"><a href="multiple-treatment-trials.html#degrees-of-freedom-1"><i class="fa fa-check"></i><b>6.5.3</b> Degrees of Freedom</a></li>
<li class="chapter" data-level="6.5.4" data-path="multiple-treatment-trials.html"><a href="multiple-treatment-trials.html#mean-square"><i class="fa fa-check"></i><b>6.5.4</b> Mean Square</a></li>
<li class="chapter" data-level="6.5.5" data-path="multiple-treatment-trials.html"><a href="multiple-treatment-trials.html#f-value"><i class="fa fa-check"></i><b>6.5.5</b> F-Value</a></li>
<li class="chapter" data-level="6.5.6" data-path="multiple-treatment-trials.html"><a href="multiple-treatment-trials.html#p-value-1"><i class="fa fa-check"></i><b>6.5.6</b> P-value</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="multiple-treatment-trials.html"><a href="multiple-treatment-trials.html#visualizing-how-the-anova-table-relates-to-variance"><i class="fa fa-check"></i><b>6.6</b> Visualizing How the Anova Table Relates to Variance</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="multiple-treatment-designs.html"><a href="multiple-treatment-designs.html"><i class="fa fa-check"></i><b>7</b> Multiple Treatment Designs</a>
<ul>
<li class="chapter" data-level="7.1" data-path="multiple-treatment-designs.html"><a href="multiple-treatment-designs.html#randomized-complete-block-design"><i class="fa fa-check"></i><b>7.1</b> Randomized Complete Block Design</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="multiple-treatment-designs.html"><a href="multiple-treatment-designs.html#case-study-randomized-complete-block-design"><i class="fa fa-check"></i><b>7.1.1</b> Case Study: Randomized Complete Block Design</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="multiple-treatment-designs.html"><a href="multiple-treatment-designs.html#factorial-design"><i class="fa fa-check"></i><b>7.2</b> Factorial Design</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="multiple-treatment-designs.html"><a href="multiple-treatment-designs.html#case-study-1-1"><i class="fa fa-check"></i><b>7.2.1</b> Case Study 1</a></li>
<li class="chapter" data-level="7.2.2" data-path="multiple-treatment-designs.html"><a href="multiple-treatment-designs.html#case-study-2-1"><i class="fa fa-check"></i><b>7.2.2</b> Case Study 2</a></li>
<li class="chapter" data-level="7.2.3" data-path="multiple-treatment-designs.html"><a href="multiple-treatment-designs.html#discussing-interactions"><i class="fa fa-check"></i><b>7.2.3</b> Discussing Interactions</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="multiple-treatment-designs.html"><a href="multiple-treatment-designs.html#split-plot-design"><i class="fa fa-check"></i><b>7.3</b> Split-Plot Design</a></li>
<li class="chapter" data-level="7.4" data-path="multiple-treatment-designs.html"><a href="multiple-treatment-designs.html#linear-additive-model-3"><i class="fa fa-check"></i><b>7.4</b> Linear Additive Model</a></li>
<li class="chapter" data-level="7.5" data-path="multiple-treatment-designs.html"><a href="multiple-treatment-designs.html#conclusion-1"><i class="fa fa-check"></i><b>7.5</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="means-separation-and-data-presentation.html"><a href="means-separation-and-data-presentation.html"><i class="fa fa-check"></i><b>8</b> Means Separation and Data Presentation</a>
<ul>
<li class="chapter" data-level="8.1" data-path="means-separation-and-data-presentation.html"><a href="means-separation-and-data-presentation.html#case-study-4"><i class="fa fa-check"></i><b>8.1</b> Case Study</a></li>
<li class="chapter" data-level="8.2" data-path="means-separation-and-data-presentation.html"><a href="means-separation-and-data-presentation.html#least-significant-difference"><i class="fa fa-check"></i><b>8.2</b> Least Significant Difference</a></li>
<li class="chapter" data-level="8.3" data-path="means-separation-and-data-presentation.html"><a href="means-separation-and-data-presentation.html#lsd-output-in-r"><i class="fa fa-check"></i><b>8.3</b> LSD Output in R</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="means-separation-and-data-presentation.html"><a href="means-separation-and-data-presentation.html#statistics-table"><i class="fa fa-check"></i><b>8.3.1</b> Statistics Table</a></li>
<li class="chapter" data-level="8.3.2" data-path="means-separation-and-data-presentation.html"><a href="means-separation-and-data-presentation.html#means-table"><i class="fa fa-check"></i><b>8.3.2</b> Means Table</a></li>
<li class="chapter" data-level="8.3.3" data-path="means-separation-and-data-presentation.html"><a href="means-separation-and-data-presentation.html#groups-table"><i class="fa fa-check"></i><b>8.3.3</b> Groups Table</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="means-separation-and-data-presentation.html"><a href="means-separation-and-data-presentation.html#comparisonwise-versus-experimentwise-error"><i class="fa fa-check"></i><b>8.4</b> Comparisonwise versus Experimentwise Error</a></li>
<li class="chapter" data-level="8.5" data-path="means-separation-and-data-presentation.html"><a href="means-separation-and-data-presentation.html#tukeys-honest-significant-difference"><i class="fa fa-check"></i><b>8.5</b> Tukey’s Honest Significant Difference</a></li>
<li class="chapter" data-level="8.6" data-path="means-separation-and-data-presentation.html"><a href="means-separation-and-data-presentation.html#linear-contrast"><i class="fa fa-check"></i><b>8.6</b> Linear Contrast</a>
<ul>
<li class="chapter" data-level="8.6.1" data-path="means-separation-and-data-presentation.html"><a href="means-separation-and-data-presentation.html#coefficients"><i class="fa fa-check"></i><b>8.6.1</b> Coefficients</a></li>
<li class="chapter" data-level="8.6.2" data-path="means-separation-and-data-presentation.html"><a href="means-separation-and-data-presentation.html#linear-contrasts-with-r"><i class="fa fa-check"></i><b>8.6.2</b> Linear Contrasts with R</a></li>
</ul></li>
<li class="chapter" data-level="8.7" data-path="means-separation-and-data-presentation.html"><a href="means-separation-and-data-presentation.html#means-presentation"><i class="fa fa-check"></i><b>8.7</b> Means Presentation</a>
<ul>
<li class="chapter" data-level="8.7.1" data-path="means-separation-and-data-presentation.html"><a href="means-separation-and-data-presentation.html#means-tables"><i class="fa fa-check"></i><b>8.7.1</b> Means Tables</a></li>
<li class="chapter" data-level="8.7.2" data-path="means-separation-and-data-presentation.html"><a href="means-separation-and-data-presentation.html#plotting-means"><i class="fa fa-check"></i><b>8.7.2</b> Plotting Means</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="messy-and-missing-data.html"><a href="messy-and-missing-data.html"><i class="fa fa-check"></i><b>9</b> Messy and Missing Data</a>
<ul>
<li class="chapter" data-level="9.1" data-path="messy-and-missing-data.html"><a href="messy-and-missing-data.html#inspecting-data-for-normal-distributions"><i class="fa fa-check"></i><b>9.1</b> Inspecting data for Normal Distributions</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="messy-and-missing-data.html"><a href="messy-and-missing-data.html#histograms-1"><i class="fa fa-check"></i><b>9.1.1</b> Histograms</a></li>
<li class="chapter" data-level="9.1.2" data-path="messy-and-missing-data.html"><a href="messy-and-missing-data.html#rank-percentile-plots"><i class="fa fa-check"></i><b>9.1.2</b> Rank Percentile Plots</a></li>
<li class="chapter" data-level="9.1.3" data-path="messy-and-missing-data.html"><a href="messy-and-missing-data.html#box-plots"><i class="fa fa-check"></i><b>9.1.3</b> Box Plots</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="messy-and-missing-data.html"><a href="messy-and-missing-data.html#inspecting-data-for-equal-variances"><i class="fa fa-check"></i><b>9.2</b> Inspecting Data for Equal Variances</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="messy-and-missing-data.html"><a href="messy-and-missing-data.html#mean-variance-plot"><i class="fa fa-check"></i><b>9.2.1</b> Mean-Variance Plot</a></li>
<li class="chapter" data-level="9.2.2" data-path="messy-and-missing-data.html"><a href="messy-and-missing-data.html#homogeneity-of-variance-tests"><i class="fa fa-check"></i><b>9.2.2</b> Homogeneity of Variance Tests</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="messy-and-missing-data.html"><a href="messy-and-missing-data.html#dealing-with-messy-data"><i class="fa fa-check"></i><b>9.3</b> Dealing with Messy Data</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="messy-and-missing-data.html"><a href="messy-and-missing-data.html#outliers"><i class="fa fa-check"></i><b>9.3.1</b> Outliers</a></li>
<li class="chapter" data-level="9.3.2" data-path="messy-and-missing-data.html"><a href="messy-and-missing-data.html#non-normal-data-and-unequal-variances"><i class="fa fa-check"></i><b>9.3.2</b> Non-normal Data and Unequal Variances</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="messy-and-missing-data.html"><a href="messy-and-missing-data.html#dealing-with-missing-data"><i class="fa fa-check"></i><b>9.4</b> Dealing with Missing Data</a></li>
<li class="chapter" data-level="9.5" data-path="messy-and-missing-data.html"><a href="messy-and-missing-data.html#summary"><i class="fa fa-check"></i><b>9.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="correlation-and-simple-regression.html"><a href="correlation-and-simple-regression.html"><i class="fa fa-check"></i><b>10</b> Correlation and Simple Regression</a>
<ul>
<li class="chapter" data-level="10.1" data-path="correlation-and-simple-regression.html"><a href="correlation-and-simple-regression.html#correlation"><i class="fa fa-check"></i><b>10.1</b> Correlation</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="correlation-and-simple-regression.html"><a href="correlation-and-simple-regression.html#case-study-cucumber"><i class="fa fa-check"></i><b>10.1.1</b> Case Study: Cucumber</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="correlation-and-simple-regression.html"><a href="correlation-and-simple-regression.html#correlation-1"><i class="fa fa-check"></i><b>10.2</b> Correlation</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="correlation-and-simple-regression.html"><a href="correlation-and-simple-regression.html#how-is-r-calcuated-optional-reading"><i class="fa fa-check"></i><b>10.2.1</b> How Is r Calcuated (optional reading)</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="correlation-and-simple-regression.html"><a href="correlation-and-simple-regression.html#regression"><i class="fa fa-check"></i><b>10.3</b> Regression</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="correlation-and-simple-regression.html"><a href="correlation-and-simple-regression.html#case-study-5"><i class="fa fa-check"></i><b>10.3.1</b> Case Study</a></li>
<li class="chapter" data-level="10.3.2" data-path="correlation-and-simple-regression.html"><a href="correlation-and-simple-regression.html#linear-equation"><i class="fa fa-check"></i><b>10.3.2</b> Linear Equation</a></li>
<li class="chapter" data-level="10.3.3" data-path="correlation-and-simple-regression.html"><a href="correlation-and-simple-regression.html#calculating-the-regression-equation"><i class="fa fa-check"></i><b>10.3.3</b> Calculating the Regression Equation</a></li>
<li class="chapter" data-level="10.3.4" data-path="correlation-and-simple-regression.html"><a href="correlation-and-simple-regression.html#least-squares-estimate"><i class="fa fa-check"></i><b>10.3.4</b> Least-Squares Estimate</a></li>
<li class="chapter" data-level="10.3.5" data-path="correlation-and-simple-regression.html"><a href="correlation-and-simple-regression.html#significance-of-coefficients"><i class="fa fa-check"></i><b>10.3.5</b> Significance of Coefficients</a></li>
<li class="chapter" data-level="10.3.6" data-path="correlation-and-simple-regression.html"><a href="correlation-and-simple-regression.html#analysis-of-variance-4"><i class="fa fa-check"></i><b>10.3.6</b> Analysis of Variance</a></li>
<li class="chapter" data-level="10.3.7" data-path="correlation-and-simple-regression.html"><a href="correlation-and-simple-regression.html#measuring-model-fit-with-r-square"><i class="fa fa-check"></i><b>10.3.7</b> Measuring Model Fit with R-Square</a></li>
<li class="chapter" data-level="10.3.8" data-path="correlation-and-simple-regression.html"><a href="correlation-and-simple-regression.html#checking-whether-the-linear-model-is-appropriate"><i class="fa fa-check"></i><b>10.3.8</b> Checking whether the Linear Model is Appropriate</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="correlation-and-simple-regression.html"><a href="correlation-and-simple-regression.html#extrapolation"><i class="fa fa-check"></i><b>10.4</b> Extrapolation</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="nonlinear-relationships-and-multiple-linear-regression.html"><a href="nonlinear-relationships-and-multiple-linear-regression.html"><i class="fa fa-check"></i><b>11</b> Nonlinear Relationships and Multiple Linear Regression</a>
<ul>
<li class="chapter" data-level="11.1" data-path="nonlinear-relationships-and-multiple-linear-regression.html"><a href="nonlinear-relationships-and-multiple-linear-regression.html#multiplie-linear-regression"><i class="fa fa-check"></i><b>11.1</b> Multiplie Linear Regression</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="nonlinear-relationships-and-multiple-linear-regression.html"><a href="nonlinear-relationships-and-multiple-linear-regression.html#case-study-modelling-yield-by-county"><i class="fa fa-check"></i><b>11.1.1</b> Case Study: Modelling Yield by County</a></li>
<li class="chapter" data-level="11.1.2" data-path="nonlinear-relationships-and-multiple-linear-regression.html"><a href="nonlinear-relationships-and-multiple-linear-regression.html#beware-of-bloated-models"><i class="fa fa-check"></i><b>11.1.2</b> Beware of Bloated Models</a></li>
<li class="chapter" data-level="11.1.3" data-path="nonlinear-relationships-and-multiple-linear-regression.html"><a href="nonlinear-relationships-and-multiple-linear-regression.html#methods-for-avoiding-bloated-models"><i class="fa fa-check"></i><b>11.1.3</b> Methods for Avoiding Bloated Models</a></li>
<li class="chapter" data-level="11.1.4" data-path="nonlinear-relationships-and-multiple-linear-regression.html"><a href="nonlinear-relationships-and-multiple-linear-regression.html#tunning-and-comparing-models"><i class="fa fa-check"></i><b>11.1.4</b> Tunning and Comparing Models</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="nonlinear-relationships-and-multiple-linear-regression.html"><a href="nonlinear-relationships-and-multiple-linear-regression.html#nonlinear-relationships"><i class="fa fa-check"></i><b>11.2</b> Nonlinear Relationships</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="nonlinear-relationships-and-multiple-linear-regression.html"><a href="nonlinear-relationships-and-multiple-linear-regression.html#fitting-nonlinear-responses-with-linear-regression"><i class="fa fa-check"></i><b>11.2.1</b> Fitting Nonlinear Responses with Linear Regression</a></li>
<li class="chapter" data-level="11.2.2" data-path="nonlinear-relationships-and-multiple-linear-regression.html"><a href="nonlinear-relationships-and-multiple-linear-regression.html#fitting-nonlinear-responses-with-nonlinear-regression"><i class="fa fa-check"></i><b>11.2.2</b> Fitting Nonlinear Responses with Nonlinear Regression</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="nonlinear-relationships-and-multiple-linear-regression.html"><a href="nonlinear-relationships-and-multiple-linear-regression.html#summary-1"><i class="fa fa-check"></i><b>11.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="spatial-statistics.html"><a href="spatial-statistics.html"><i class="fa fa-check"></i><b>12</b> Spatial Statistics</a>
<ul>
<li class="chapter" data-level="12.1" data-path="spatial-statistics.html"><a href="spatial-statistics.html#projection-general"><i class="fa fa-check"></i><b>12.1</b> Projection (General)</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="spatial-statistics.html"><a href="spatial-statistics.html#wgs-84-epsg-4236"><i class="fa fa-check"></i><b>12.1.1</b> WGS 84 (EPSG: 4236)</a></li>
<li class="chapter" data-level="12.1.2" data-path="spatial-statistics.html"><a href="spatial-statistics.html#mercator-epsg-3857"><i class="fa fa-check"></i><b>12.1.2</b> Mercator (EPSG: 3857)</a></li>
<li class="chapter" data-level="12.1.3" data-path="spatial-statistics.html"><a href="spatial-statistics.html#us-national-atlas-equal-area-epsg-2163"><i class="fa fa-check"></i><b>12.1.3</b> US National Atlas Equal Area (EPSG: 2163)</a></li>
<li class="chapter" data-level="12.1.4" data-path="spatial-statistics.html"><a href="spatial-statistics.html#utm-zone-11n-epsg-2955"><i class="fa fa-check"></i><b>12.1.4</b> UTM Zone 11N (EPSG: 2955)</a></li>
<li class="chapter" data-level="12.1.5" data-path="spatial-statistics.html"><a href="spatial-statistics.html#projection-summary"><i class="fa fa-check"></i><b>12.1.5</b> Projection Summary</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="spatial-statistics.html"><a href="spatial-statistics.html#shape-files"><i class="fa fa-check"></i><b>12.2</b> Shape Files</a>
<ul>
<li class="chapter" data-level="12.2.1" data-path="spatial-statistics.html"><a href="spatial-statistics.html#case-study-soybean-yield-in-iowa"><i class="fa fa-check"></i><b>12.2.1</b> Case Study: Soybean Yield in Iowa</a></li>
<li class="chapter" data-level="12.2.2" data-path="spatial-statistics.html"><a href="spatial-statistics.html#ssurgo"><i class="fa fa-check"></i><b>12.2.2</b> SSURGO</a></li>
<li class="chapter" data-level="12.2.3" data-path="spatial-statistics.html"><a href="spatial-statistics.html#operations-with-shapes"><i class="fa fa-check"></i><b>12.2.3</b> Operations with Shapes</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="spatial-statistics.html"><a href="spatial-statistics.html#rasters"><i class="fa fa-check"></i><b>12.3</b> Rasters</a>
<ul>
<li class="chapter" data-level="12.3.1" data-path="spatial-statistics.html"><a href="spatial-statistics.html#interpolation"><i class="fa fa-check"></i><b>12.3.1</b> Interpolation</a></li>
<li class="chapter" data-level="12.3.2" data-path="spatial-statistics.html"><a href="spatial-statistics.html#kriging"><i class="fa fa-check"></i><b>12.3.2</b> Kriging</a></li>
<li class="chapter" data-level="12.3.3" data-path="spatial-statistics.html"><a href="spatial-statistics.html#operations-on-kriged-data"><i class="fa fa-check"></i><b>12.3.3</b> Operations on Kriged Data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="13" data-path="machine-learning.html"><a href="machine-learning.html"><i class="fa fa-check"></i><b>13</b> Machine Learning</a>
<ul>
<li class="chapter" data-level="13.1" data-path="machine-learning.html"><a href="machine-learning.html#machine-learning-1"><i class="fa fa-check"></i><b>13.1</b> Machine Learning</a></li>
<li class="chapter" data-level="13.2" data-path="machine-learning.html"><a href="machine-learning.html#cluster-analyses"><i class="fa fa-check"></i><b>13.2</b> Cluster Analyses</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="machine-learning.html"><a href="machine-learning.html#case-study-grouping-midwestern-environments"><i class="fa fa-check"></i><b>13.2.1</b> Case Study: Grouping Midwestern Environments</a></li>
<li class="chapter" data-level="13.2.2" data-path="machine-learning.html"><a href="machine-learning.html#scaling"><i class="fa fa-check"></i><b>13.2.2</b> Scaling</a></li>
<li class="chapter" data-level="13.2.3" data-path="machine-learning.html"><a href="machine-learning.html#clustering-animation"><i class="fa fa-check"></i><b>13.2.3</b> Clustering Animation</a></li>
<li class="chapter" data-level="13.2.4" data-path="machine-learning.html"><a href="machine-learning.html#county-cluster-analysis"><i class="fa fa-check"></i><b>13.2.4</b> County Cluster Analysis</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="machine-learning.html"><a href="machine-learning.html#k-nearest-neighbors"><i class="fa fa-check"></i><b>13.3</b> k-Nearest-Neighbors</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="machine-learning.html"><a href="machine-learning.html#case-study-guessing-county-yields-based-on-environmental-similarity"><i class="fa fa-check"></i><b>13.3.1</b> Case Study: Guessing County Yields based on Environmental Similarity</a></li>
<li class="chapter" data-level="13.3.2" data-path="machine-learning.html"><a href="machine-learning.html#scaling-1"><i class="fa fa-check"></i><b>13.3.2</b> Scaling</a></li>
<li class="chapter" data-level="13.3.3" data-path="machine-learning.html"><a href="machine-learning.html#k-nearest-neighbor-animation"><i class="fa fa-check"></i><b>13.3.3</b> k-Nearest-Neighbor Animation</a></li>
<li class="chapter" data-level="13.3.4" data-path="machine-learning.html"><a href="machine-learning.html#choosing-k"><i class="fa fa-check"></i><b>13.3.4</b> Choosing <span class="math inline">\(k\)</span></a></li>
<li class="chapter" data-level="13.3.5" data-path="machine-learning.html"><a href="machine-learning.html#model-cross-validation"><i class="fa fa-check"></i><b>13.3.5</b> Model Cross-Validation</a></li>
<li class="chapter" data-level="13.3.6" data-path="machine-learning.html"><a href="machine-learning.html#yield-prediction-with-nearest-neighbor-analysis"><i class="fa fa-check"></i><b>13.3.6</b> Yield Prediction with Nearest Neighbor Analysis</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="machine-learning.html"><a href="machine-learning.html#classification-trees"><i class="fa fa-check"></i><b>13.4</b> Classification Trees</a>
<ul>
<li class="chapter" data-level="13.4.1" data-path="machine-learning.html"><a href="machine-learning.html#features"><i class="fa fa-check"></i><b>13.4.1</b> Features</a></li>
<li class="chapter" data-level="13.4.2" data-path="machine-learning.html"><a href="machine-learning.html#quantitative-categorical-data"><i class="fa fa-check"></i><b>13.4.2</b> Quantitative (Categorical) Data</a></li>
<li class="chapter" data-level="13.4.3" data-path="machine-learning.html"><a href="machine-learning.html#quanatitiative-continuous-data"><i class="fa fa-check"></i><b>13.4.3</b> Quanatitiative (Continuous) Data</a></li>
<li class="chapter" data-level="13.4.4" data-path="machine-learning.html"><a href="machine-learning.html#overfitting-1"><i class="fa fa-check"></i><b>13.4.4</b> Overfitting</a></li>
<li class="chapter" data-level="13.4.5" data-path="machine-learning.html"><a href="machine-learning.html#cross-validation-1"><i class="fa fa-check"></i><b>13.4.5</b> Cross Validation</a></li>
<li class="chapter" data-level="13.4.6" data-path="machine-learning.html"><a href="machine-learning.html#random-forest"><i class="fa fa-check"></i><b>13.4.6</b> Random Forest</a></li>
<li class="chapter" data-level="13.4.7" data-path="machine-learning.html"><a href="machine-learning.html#feature-importance"><i class="fa fa-check"></i><b>13.4.7</b> Feature Importance</a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="machine-learning.html"><a href="machine-learning.html#summary-2"><i class="fa fa-check"></i><b>13.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="putting-it-all-together.html"><a href="putting-it-all-together.html"><i class="fa fa-check"></i><b>14</b> Putting it all Together</a>
<ul>
<li class="chapter" data-level="14.1" data-path="putting-it-all-together.html"><a href="putting-it-all-together.html#scenario-1-yield-map-population-summary-and-z-distribution"><i class="fa fa-check"></i><b>14.1</b> Scenario 1: Yield Map (Population Summary and Z-Distribution)</a></li>
<li class="chapter" data-level="14.2" data-path="putting-it-all-together.html"><a href="putting-it-all-together.html#scenario-2-yield-estimate-sampling-t-distribution"><i class="fa fa-check"></i><b>14.2</b> Scenario 2: Yield Estimate (Sampling t-Distribution)</a></li>
<li class="chapter" data-level="14.3" data-path="putting-it-all-together.html"><a href="putting-it-all-together.html#scenario-3-side-by-side-t-test"><i class="fa fa-check"></i><b>14.3</b> Scenario 3: Side-By-Side (t-Test)</a></li>
<li class="chapter" data-level="14.4" data-path="putting-it-all-together.html"><a href="putting-it-all-together.html#scenario-4-fungicide-trial-anova-crd-or-rcbd"><i class="fa fa-check"></i><b>14.4</b> Scenario 4: Fungicide Trial (ANOVA CRD or RCBD)</a></li>
<li class="chapter" data-level="14.5" data-path="putting-it-all-together.html"><a href="putting-it-all-together.html#scenario-5-hybrid-response-to-fungicide-trial-anova-factorial-or-split-plot"><i class="fa fa-check"></i><b>14.5</b> Scenario 5: Hybrid Response to Fungicide Trial (ANOVA Factorial or Split Plot)</a></li>
<li class="chapter" data-level="14.6" data-path="putting-it-all-together.html"><a href="putting-it-all-together.html#scenario-6-foliar-rate-response-trial-linear-or-non-linear-regression"><i class="fa fa-check"></i><b>14.6</b> Scenario 6: Foliar Rate-Response Trial (Linear or Non-Linear Regression)</a></li>
<li class="chapter" data-level="14.7" data-path="putting-it-all-together.html"><a href="putting-it-all-together.html#scenario-7-application-map-shapefiles-and-rasters"><i class="fa fa-check"></i><b>14.7</b> Scenario 7: Application Map (Shapefiles and Rasters)</a></li>
<li class="chapter" data-level="14.8" data-path="putting-it-all-together.html"><a href="putting-it-all-together.html#scenario-8-yield-prediction-multiple-linear-regression-and-other-predictive-models"><i class="fa fa-check"></i><b>14.8</b> Scenario 8: Yield Prediction (Multiple Linear Regression and other Predictive Models)</a></li>
<li class="chapter" data-level="14.9" data-path="putting-it-all-together.html"><a href="putting-it-all-together.html#summary-3"><i class="fa fa-check"></i><b>14.9</b> Summary</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Data Science for Agricultural Professionals</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="understanding-statistical-tests" class="section level1" number="5">
<h1><span class="header-section-number">Chapter 5</span> Understanding Statistical Tests</h1>
<p>In the last unit, we introduced the concept of statistical testing and, although I endeavor to make this course as practical and painless as possible, I believe it worthwhile to spend a unit on some of the theory of statistical testing. This will help reinforce what we have learned so far in this course, and prepare us for the other statistical tests that lie ahead. Otherwise, it is easy to become ambiguous about what we are really testing, and unclear in reporting our results.</p>
<p>In the last unit, we discussed experimental design and quickly jumped into data analysis. This unit, we will walk through the thought processes that surround our trial, including:
- identifying our research question
- creating a model from our question
- identifying the hypotheses our data will be used to test
- recognizing that we can mistakingly accept or reject these hypotheses
- understanding how the confidence interval and p-value describe our measured difference
- incorporating pre-existing knowledge into our hypotheses and tests</p>
<p>This list seems intimidating, but we will take our time and break these down into as much plain language as statistics will allow.</p>
<div id="research-question" class="section level2" number="5.1">
<h2><span class="header-section-number">5.1</span> Research Question</h2>
<p>As I have likely said before in this course, the first think you must have to design an experiment is a clear, testable research question. The question should be answerable using quantitative data and specific about what those data will measure. Here are some examples of bad and good questions:</p>
<p>Bad: Is this fertilizer better than another? <br>
Good: Does corn treated with 6-24-6 fertilizer at planting differ in yield from corn that is not treated with an in-furrow starter.</p>
<p>Bad: Is the winter wheat variety MH666 (“the Beast”) different than variety MH007 (“the Bond”)? <br>
Good: Does variety MH666 differ in test weight from variety MH007 ?</p>
<p>Bad: Does herbicide deposition agent “Stick-It!” perform differently than agent “Get-Down!” ? <br>
Good: Do “Stick-It!” and “Get-Down!” differ in the number of live weeds two weeks after their application with glyphosate?</p>
<p>Remember to be clear about what we are measuring. Otherwise, it is unclear whether we are testing fertilizer affects on corn yield or moisture at harvest. We don’t know whether we are comparing winter wheat yield or head scab. We don’t know whether we are measuring the effect of our deposition agent on weed survival or crop injury.</p>
</div>
<div id="the-model" class="section level2" number="5.2">
<h2><span class="header-section-number">5.2</span> The Model</h2>
<p>The word “model” probably makes you shudder and think of a crowded blackboard filled with mathematical equations.</p>
<!-- ![models]("roman-mager-5mZ_M06Fc9g-unsplash.jpg") -->
<p>Yes, models can be quite complex. All of you have worked with models, however, and most of you should recall this one:</p>
<p><span class="math display">\[ y = b + mx  \]</span>
Where <span class="math inline">\(y\)</span> is the vertical coordinate of a point on a graph, <span class="math inline">\(x\)</span> is its horizontal coordinate, and <span class="math inline">\(b\)</span> is the Y-intercept (where the line crosses the y-axis). The most interesting variable is often <span class="math inline">\(m\)</span>, the slope. The slope is the unit increase in y with each unit increase in x.</p>
<p>Suppose we took a field of corn and conducted a side-by-side trial where half of the plots were sidedressed with 150 lbs treated with an N stabilizer. The other half were sidedressed with 150 lbs actual N plus 1 unit of nitrogen stabilizer. The mean yield of plots treated with N plus nitrogen stabilizer was 195 bu and the mean yield of plots treated with N alone was 175 bu. How could we express this with a slope equation?</p>
<p>First, let’s state this as a table. We will express the N stabilizer quantitatively. The “No Stabilizer” treatment included zero units of N stabilizer. The “Stabilizer” treatment received 1 unit of stabilizer.</p>
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="understanding-statistical-tests.html#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb69-2"><a href="understanding-statistical-tests.html#cb69-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-3"><a href="understanding-statistical-tests.html#cb69-3" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1776</span>)</span>
<span id="cb69-4"><a href="understanding-statistical-tests.html#cb69-4" aria-hidden="true" tabindex="-1"></a><span class="st">`</span><span class="at">No Stabilizer</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">4</span>, <span class="at">mean=</span><span class="dv">175</span>, <span class="at">sd =</span> <span class="dv">5</span>)</span>
<span id="cb69-5"><a href="understanding-statistical-tests.html#cb69-5" aria-hidden="true" tabindex="-1"></a><span class="st">`</span><span class="at">Stabilizer</span><span class="st">`</span> <span class="ot">=</span> <span class="fu">rnorm</span>(<span class="dv">4</span>, <span class="at">mean =</span> <span class="dv">195</span>, <span class="at">sd=</span><span class="dv">5</span>)</span>
<span id="cb69-6"><a href="understanding-statistical-tests.html#cb69-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-7"><a href="understanding-statistical-tests.html#cb69-7" aria-hidden="true" tabindex="-1"></a>original_data <span class="ot">=</span> <span class="fu">cbind</span>(<span class="st">`</span><span class="at">No Stabilizer</span><span class="st">`</span>, <span class="st">`</span><span class="at">Stabilizer</span><span class="st">`</span>) <span class="sc">%&gt;%</span></span>
<span id="cb69-8"><a href="understanding-statistical-tests.html#cb69-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.data.frame</span>() </span>
<span id="cb69-9"><a href="understanding-statistical-tests.html#cb69-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-10"><a href="understanding-statistical-tests.html#cb69-10" aria-hidden="true" tabindex="-1"></a>means_table <span class="ot">=</span> original_data <span class="sc">%&gt;%</span></span>
<span id="cb69-11"><a href="understanding-statistical-tests.html#cb69-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(Treatment, Yield) <span class="sc">%&gt;%</span></span>
<span id="cb69-12"><a href="understanding-statistical-tests.html#cb69-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(Treatment) <span class="sc">%&gt;%</span></span>
<span id="cb69-13"><a href="understanding-statistical-tests.html#cb69-13" aria-hidden="true" tabindex="-1"></a>  <span class="fu">summarise</span>(<span class="at">Yield =</span> <span class="fu">mean</span>(Yield)) <span class="sc">%&gt;%</span></span>
<span id="cb69-14"><a href="understanding-statistical-tests.html#cb69-14" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb69-15"><a href="understanding-statistical-tests.html#cb69-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Yield =</span> <span class="fu">round</span>(Yield, <span class="dv">1</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb69-16"><a href="understanding-statistical-tests.html#cb69-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Nitrogen =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">1</span>)) <span class="sc">%&gt;%</span></span>
<span id="cb69-17"><a href="understanding-statistical-tests.html#cb69-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(Treatment, Nitrogen, Yield) <span class="sc">%&gt;%</span></span>
<span id="cb69-18"><a href="understanding-statistical-tests.html#cb69-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">column_to_rownames</span>(<span class="at">var =</span> <span class="st">&quot;Treatment&quot;</span>) </span>
<span id="cb69-19"><a href="understanding-statistical-tests.html#cb69-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-20"><a href="understanding-statistical-tests.html#cb69-20" aria-hidden="true" tabindex="-1"></a>mean_yield <span class="ot">=</span> <span class="fu">mean</span>(means_table<span class="sc">$</span>Yield)</span>
<span id="cb69-21"><a href="understanding-statistical-tests.html#cb69-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb69-22"><a href="understanding-statistical-tests.html#cb69-22" aria-hidden="true" tabindex="-1"></a>means_table</span></code></pre></div>
<pre><code>##               Nitrogen Yield
## No Stabilizer        0 177.7
## Stabilizer           1 198.0</code></pre>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="understanding-statistical-tests.html#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="co"># yield = c(175, 195, 185)</span></span>
<span id="cb71-2"><a href="understanding-statistical-tests.html#cb71-2" aria-hidden="true" tabindex="-1"></a><span class="co"># nitrogen = c(0, 1, 0.5)</span></span>
<span id="cb71-3"><a href="understanding-statistical-tests.html#cb71-3" aria-hidden="true" tabindex="-1"></a><span class="co"># original_data = cbind(nitrogen, yield) %&gt;%</span></span>
<span id="cb71-4"><a href="understanding-statistical-tests.html#cb71-4" aria-hidden="true" tabindex="-1"></a><span class="co">#   as.data.frame()</span></span>
<span id="cb71-5"><a href="understanding-statistical-tests.html#cb71-5" aria-hidden="true" tabindex="-1"></a><span class="co"># rownames(original_data) = c(&quot;No Stabilizer&quot;, &quot;Stabilizer&quot;, &quot;Mean&quot;)</span></span>
<span id="cb71-6"><a href="understanding-statistical-tests.html#cb71-6" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb71-7"><a href="understanding-statistical-tests.html#cb71-7" aria-hidden="true" tabindex="-1"></a><span class="co"># original_data</span></span></code></pre></div>
<p>In creating this table, we also calculated the mean stabilizer rate and corn yield across all plots. These are are population means for the field.</p>
<p>Now, let’s express the stabilizer rate and yield little differently, this time by their differences from their population mean. In half of the plots, the N stabilizer rate was 0.5 less than the population mean of 187.9; in the other half, the rate was 0.5 greater. Similarly, the yield in half of the plots was about 10 bushels less than the population mean of 188.9; in the other half of the plots, it was 10 bushels greater. Our table now looks like this:</p>
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="understanding-statistical-tests.html#cb72-1" aria-hidden="true" tabindex="-1"></a>centered_data <span class="ot">=</span> means_table <span class="sc">%&gt;%</span></span>
<span id="cb72-2"><a href="understanding-statistical-tests.html#cb72-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale</span>(<span class="at">scale =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb72-3"><a href="understanding-statistical-tests.html#cb72-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.data.frame</span>() <span class="sc">%&gt;%</span></span>
<span id="cb72-4"><a href="understanding-statistical-tests.html#cb72-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Yield =</span> <span class="fu">round</span>(Yield, <span class="dv">1</span>))</span>
<span id="cb72-5"><a href="understanding-statistical-tests.html#cb72-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb72-6"><a href="understanding-statistical-tests.html#cb72-6" aria-hidden="true" tabindex="-1"></a>centered_data</span></code></pre></div>
<pre><code>##               Nitrogen Yield
## No Stabilizer     -0.5 -10.2
## Stabilizer         0.5  10.2</code></pre>
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="understanding-statistical-tests.html#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb74-2"><a href="understanding-statistical-tests.html#cb74-2" aria-hidden="true" tabindex="-1"></a><span class="co"># yield = c(-10, 10, 0)</span></span>
<span id="cb74-3"><a href="understanding-statistical-tests.html#cb74-3" aria-hidden="true" tabindex="-1"></a><span class="co"># nitrogen = c(-0.5, 0.5, 0)</span></span>
<span id="cb74-4"><a href="understanding-statistical-tests.html#cb74-4" aria-hidden="true" tabindex="-1"></a><span class="co"># centered_data = cbind(nitrogen, yield) %&gt;%</span></span>
<span id="cb74-5"><a href="understanding-statistical-tests.html#cb74-5" aria-hidden="true" tabindex="-1"></a><span class="co">#   as.data.frame()</span></span>
<span id="cb74-6"><a href="understanding-statistical-tests.html#cb74-6" aria-hidden="true" tabindex="-1"></a><span class="co"># rownames(centered_data) = c(&quot;No Stabilizer&quot;, &quot;Stabilizer&quot;, &quot;Mean&quot;)</span></span>
<span id="cb74-7"><a href="understanding-statistical-tests.html#cb74-7" aria-hidden="true" tabindex="-1"></a><span class="co"># </span></span>
<span id="cb74-8"><a href="understanding-statistical-tests.html#cb74-8" aria-hidden="true" tabindex="-1"></a><span class="co"># centered_data</span></span></code></pre></div>
<p>What we have just done is a statistical process called <em>center scaling</em>. Centering expresses measures by their distance from the population mean, instead of as absolute values.</p>
<p>Now let’s plot this out using our line equation. <span class="math inline">\(y\)</span> equals yield. <span class="math inline">\(x\)</span> equals nitrogen rate. <span class="math inline">\(b\)</span> equals the mean yield, the y-intercept, which is zero in our centered data.</p>
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="understanding-statistical-tests.html#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggpubr)</span>
<span id="cb75-2"><a href="understanding-statistical-tests.html#cb75-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-3"><a href="understanding-statistical-tests.html#cb75-3" aria-hidden="true" tabindex="-1"></a>means_plot <span class="ot">=</span> centered_data <span class="sc">%&gt;%</span></span>
<span id="cb75-4"><a href="understanding-statistical-tests.html#cb75-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Nitrogen, <span class="at">y=</span>Yield)) <span class="sc">+</span></span>
<span id="cb75-5"><a href="understanding-statistical-tests.html#cb75-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">color=</span><span class="st">&quot;blue&quot;</span>, <span class="at">size =</span><span class="dv">5</span>) <span class="sc">+</span> </span>
<span id="cb75-6"><a href="understanding-statistical-tests.html#cb75-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_line</span>(<span class="at">size =</span> <span class="fl">1.5</span>) </span>
<span id="cb75-7"><a href="understanding-statistical-tests.html#cb75-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb75-8"><a href="understanding-statistical-tests.html#cb75-8" aria-hidden="true" tabindex="-1"></a>means_plot <span class="sc">+</span> </span>
<span id="cb75-9"><a href="understanding-statistical-tests.html#cb75-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">x =</span> Nitrogen <span class="sc">+</span> <span class="fl">0.06</span>, <span class="at">y =</span> Yield, <span class="at">label =</span> Yield), <span class="at">size =</span> <span class="dv">5</span>)</span></code></pre></div>
<p><img src="data-science-for-agricultural-professionals_files/figure-html/unnamed-chunk-72-1.png" width="672" /></p>
<p>Ta da: our line plot. If we were to write this as a linear equation, it would be:</p>
<p><span class="math display">\[ Yield = 0 + 20*Stabilizer\]</span>
Thus, as the N stabilizer rate increase from 0 (no stabilizer) to 1 (stabilizer), yield increases 20 bushels.</p>
<div id="treatment-effect" class="section level3" number="5.2.1">
<h3><span class="header-section-number">5.2.1</span> Treatment Effect</h3>
<p>Another way of expressing the effect of the treatment levels is in terms of their distance from the mean yield across all plots. Where sidedressed with nitrogen alone, our mean yield is equal to the population mean minus 10. Conversely, where we sidedressed with nitrogen plus stabilizer, our yield is the population mean <em>plus</em> 10.2. We can express these treatment effects as:</p>
<p><span class="math display">\[Unstabilized : T_0 = -10.2\]</span>
<span class="math display">\[Stabilized: T_1 = +10.2\]</span></p>
<p>Our mean yield when corn is sidedressed with N without stabilizer is then equal to the mean yield across all plots plus the treatment effect:</p>
<p><span class="math display">\[Unstabilized: Y_0 = \mu + T_0 \]</span>
<span class="math display">\[Stabilized: Y_1 = \mu + T_1 \]</span></p>
<p>We can prove this to ourselves by plugging in the actual yields for <span class="math inline">\(Y\)</span> and <span class="math inline">\(\mu\)</span> and the actual treatment effects for <span class="math inline">\(T_0\)</span> and <span class="math inline">\(T_1\)</span>:
<span class="math display">\[ Unstabilized: 175 = 185 + (-10.2) \]</span>
<span class="math display">\[Stabilized: Y_1 = 185 + (+10.2) \]</span></p>
</div>
<div id="error-effect" class="section level3" number="5.2.2">
<h3><span class="header-section-number">5.2.2</span> Error Effect</h3>
<p>The treatment effect is known as a <em>fixed</em> effect: we assume it will be consistent across all plots within our trial. That said, will every plot that receives nitrogen plus stabilizer will yield 195 bushels? Will every field sidedressed with nitrogen without stabilizer yield 175?</p>
<p>Of course not. Any yield map will show variation in yield within a field, even when the entire field has been managed uniformly. Differences in soil texture and microclimates, inconsistencies in field operations, and inaccuracies in measuring equipment contribute to variations in the values recorded recorded. These variations will also add to or subtract from the mean yield across all plots.</p>
<p>We can visualize this in the plot below.</p>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="understanding-statistical-tests.html#cb76-1" aria-hidden="true" tabindex="-1"></a>centered_original_data_by_trt <span class="ot">=</span> original_data <span class="sc">%&gt;%</span></span>
<span id="cb76-2"><a href="understanding-statistical-tests.html#cb76-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(Nitrogen, Yield) <span class="sc">%&gt;%</span></span>
<span id="cb76-3"><a href="understanding-statistical-tests.html#cb76-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Nitrogen =</span> <span class="fu">gsub</span>(<span class="st">&quot;No Stabilizer&quot;</span>, <span class="sc">-</span><span class="fl">0.5</span>, Nitrogen)) <span class="sc">%&gt;%</span></span>
<span id="cb76-4"><a href="understanding-statistical-tests.html#cb76-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Nitrogen =</span> <span class="fu">gsub</span>(<span class="st">&quot;Stabilizer&quot;</span>, <span class="fl">0.5</span>, Nitrogen)) <span class="sc">%&gt;%</span></span>
<span id="cb76-5"><a href="understanding-statistical-tests.html#cb76-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">mu =</span> <span class="fu">mean</span>(Yield)) <span class="sc">%&gt;%</span></span>
<span id="cb76-6"><a href="understanding-statistical-tests.html#cb76-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">group_by</span>(Nitrogen) <span class="sc">%&gt;%</span></span>
<span id="cb76-7"><a href="understanding-statistical-tests.html#cb76-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">T =</span> <span class="fu">mean</span>(Yield) <span class="sc">-</span> mu) <span class="sc">%&gt;%</span></span>
<span id="cb76-8"><a href="understanding-statistical-tests.html#cb76-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ungroup</span>() <span class="sc">%&gt;%</span></span>
<span id="cb76-9"><a href="understanding-statistical-tests.html#cb76-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">E =</span> Yield <span class="sc">-</span> T <span class="sc">-</span> mu) <span class="sc">%&gt;%</span>  </span>
<span id="cb76-10"><a href="understanding-statistical-tests.html#cb76-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Effect =</span> T <span class="sc">+</span> E) <span class="sc">%&gt;%</span></span>
<span id="cb76-11"><a href="understanding-statistical-tests.html#cb76-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Nitrogen =</span> <span class="fu">as.numeric</span>(Nitrogen)) <span class="sc">%&gt;%</span></span>
<span id="cb76-12"><a href="understanding-statistical-tests.html#cb76-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">E =</span> <span class="fu">round</span>(E,<span class="dv">1</span>))</span>
<span id="cb76-13"><a href="understanding-statistical-tests.html#cb76-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb76-14"><a href="understanding-statistical-tests.html#cb76-14" aria-hidden="true" tabindex="-1"></a>means_plot <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">data =</span> centered_original_data_by_trt, <span class="fu">aes</span>(<span class="at">x =</span> Nitrogen, <span class="at">y=</span>Effect, <span class="at">label=</span>E), <span class="at">size=</span><span class="dv">3</span>, <span class="at">color=</span><span class="st">&quot;tomato&quot;</span>) <span class="sc">+</span> </span>
<span id="cb76-15"><a href="understanding-statistical-tests.html#cb76-15" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="at">data =</span> centered_original_data_by_trt, <span class="fu">aes</span>(<span class="at">x =</span> Nitrogen<span class="fl">+0.02</span>, <span class="at">y =</span> Effect, <span class="at">label =</span> E), <span class="at">hjust =</span> <span class="dv">0</span>, <span class="at">size =</span> <span class="dv">4</span>)</span></code></pre></div>
<pre><code>## Warning: Ignoring unknown aesthetics: label</code></pre>
<p><img src="data-science-for-agricultural-professionals_files/figure-html/unnamed-chunk-73-1.png" width="672" /></p>
<p>The blue points still represent the treatment mean, and the black line represents the difference between treatments. The red points are the original data – note how they are distributed around each treatment mean. Any individual observation is going to add to or subtract from its treatment mean. The value which each point adds to the treatment mean is show to the right of the point. This is the error effect for that observation.</p>
<p>Sometimes it is easier to view the experimental unit effect another way, by excluding the treatment effect so that just the effects are plotted around their mean of zero:</p>
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="understanding-statistical-tests.html#cb78-1" aria-hidden="true" tabindex="-1"></a>centered_original_data_by_trt <span class="sc">%&gt;%</span></span>
<span id="cb78-2"><a href="understanding-statistical-tests.html#cb78-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> Nitrogen, <span class="at">y=</span>E)) <span class="sc">+</span> </span>
<span id="cb78-3"><a href="understanding-statistical-tests.html#cb78-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="at">size =</span> <span class="dv">3</span>, <span class="at">color=</span><span class="st">&quot;tomato&quot;</span>) <span class="sc">+</span></span>
<span id="cb78-4"><a href="understanding-statistical-tests.html#cb78-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="fu">aes</span>(<span class="at">yintercept =</span> <span class="dv">0</span>), <span class="at">size=</span><span class="dv">1</span>)</span></code></pre></div>
<p><img src="data-science-for-agricultural-professionals_files/figure-html/unnamed-chunk-74-1.png" width="672" /></p>
<p>This kind of plot is often called a <em>residual plot</em>, because the error can be thought of as the unexplained, leftover (ie “residue”) effect after the population mean and and treatment effects are accounted for. When a correct model is fit to the data, about half the observations for each treatment should be greater than zero, and half below zero. The residual plot is a valuable tool to inspect and verify this assumption.</p>
<p>The yield observed in each plot, then, will be the sum of three values:
- the mean yield across all plots
- the effect of the treatment applied to that plot
- the combined effect of environment, field operations, and measurements</p>
<p>This model can be expressed as:</p>
<p><span class="math display">\[ Y_{ij} = \mu + T_i + \epsilon_{ij} \]</span></p>
<p>Where:
- <span class="math inline">\(Y_{ij}\)</span> is the yield of the <span class="math inline">\(i^{th}\)</span> treatment level in the <span class="math inline">\(j^{th}\)</span> block
- <span class="math inline">\(\mu\)</span> is the yield mean across all plots
- <span class="math inline">\(T_i\)</span> is the effect of the <span class="math inline">\(i^{th}\)</span> level of stabilizer
- <span class="math inline">\(\epsilon_{ij}\)</span> is the <em>random</em> effect associated with the plot in the <span class="math inline">\(j^{th}\)</span> block that received the <span class="math inline">\(i^{th}\)</span> level of stabilizer</p>
<p>For example, a plot in the 3rd block that received nitrogen treated with stabilizer (<span class="math inline">\(T_1\)</span>) would be indicated by the equation:</p>
<p><span class="math display">\[ Y_{13} = \mu + T_1 + \epsilon_{13} \]</span></p>
<p>If the error for this plot, <span class="math inline">\(\epsilon_{13}\)</span>, was -2, the observed yield would be:</p>
<p><span class="math display">\[ Y_{13} = 185 + 10 -2 = 193 \]</span></p>
<p>Why bother with the linear model when we simply want to know if one treatment yields more than the other? There are two reasons. First, although in agriculture we often think of field trials as testing differences, what we are really doing is using the data from those trials to <em>predict</em> future differences. In my opinion, this is one of the key differences betweeen classical statistics and data science. Classical statistics describes what haas happened in the past. Data science predicts what will happen in the future.</p>
<p>The linear model above is exactly how we would use data from this trial to predict yields if the product is used under similar conditions. Adding the stabilizer to nitrogen during sidedress will increase the mean yield for a field by 10 bushels. But any given point in that field will have a yield that is also determined by the random effects that our model cannot predict: soil and microclimate, equipment, and measurement errors.</p>
<p>Second, the linear model illustrates what statistics will test for us. Ultimately, every statistical test is a comparison between fixed and random effects: what explains the differences in our observations more: the fixed effects (our treatment) or random effects (error)? In our current example, we can visualize this as follows:</p>
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="understanding-statistical-tests.html#cb79-1" aria-hidden="true" tabindex="-1"></a>centered_original_data <span class="ot">=</span> original_data <span class="sc">%&gt;%</span></span>
<span id="cb79-2"><a href="understanding-statistical-tests.html#cb79-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">gather</span>(Nitrogen, Yield) <span class="sc">%&gt;%</span></span>
<span id="cb79-3"><a href="understanding-statistical-tests.html#cb79-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Nitrogen =</span> <span class="fu">gsub</span>(<span class="st">&quot;No Stabilizer&quot;</span>, <span class="sc">-</span><span class="fl">0.5</span>, Nitrogen)) <span class="sc">%&gt;%</span></span>
<span id="cb79-4"><a href="understanding-statistical-tests.html#cb79-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Nitrogen =</span> <span class="fu">gsub</span>(<span class="st">&quot;Stabilizer&quot;</span>, <span class="fl">0.5</span>, Nitrogen)) <span class="sc">%&gt;%</span></span>
<span id="cb79-5"><a href="understanding-statistical-tests.html#cb79-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Yield =</span> Yield <span class="sc">-</span> <span class="fu">mean</span>(Yield)) <span class="sc">%&gt;%</span></span>
<span id="cb79-6"><a href="understanding-statistical-tests.html#cb79-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">Nitrogen =</span> <span class="fu">as.numeric</span>(Nitrogen))</span>
<span id="cb79-7"><a href="understanding-statistical-tests.html#cb79-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-8"><a href="understanding-statistical-tests.html#cb79-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggpubr)</span>
<span id="cb79-9"><a href="understanding-statistical-tests.html#cb79-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-10"><a href="understanding-statistical-tests.html#cb79-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb79-11"><a href="understanding-statistical-tests.html#cb79-11" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(pBrackets)</span></code></pre></div>
<pre><code>## Warning: package &#39;pBrackets&#39; was built under R version 4.0.5</code></pre>
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="understanding-statistical-tests.html#cb81-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(grid)</span>
<span id="cb81-2"><a href="understanding-statistical-tests.html#cb81-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-3"><a href="understanding-statistical-tests.html#cb81-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-4"><a href="understanding-statistical-tests.html#cb81-4" aria-hidden="true" tabindex="-1"></a>means_plot <span class="sc">+</span> <span class="fu">geom_point</span>(<span class="at">data =</span> centered_original_data, <span class="fu">aes</span>(<span class="at">x =</span> Nitrogen, <span class="at">y=</span>Yield), <span class="at">size=</span><span class="dv">3</span>, <span class="at">color=</span><span class="st">&quot;tomato&quot;</span>) <span class="sc">+</span> </span>
<span id="cb81-5"><a href="understanding-statistical-tests.html#cb81-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">x=</span><span class="sc">-</span><span class="fl">0.40</span>, <span class="at">y=</span><span class="sc">-</span><span class="dv">10</span>), <span class="at">label=</span><span class="st">&quot;Does the spread of</span><span class="sc">\n</span><span class="st">individuals within a treatment</span><span class="sc">\n</span><span class="st">explain more of the variance?&quot;</span>, </span>
<span id="cb81-6"><a href="understanding-statistical-tests.html#cb81-6" aria-hidden="true" tabindex="-1"></a>            <span class="at">hjust=</span><span class="dv">0</span>, <span class="at">vjust=</span><span class="dv">1</span>, <span class="at">size=</span><span class="dv">5</span>) <span class="sc">+</span></span>
<span id="cb81-7"><a href="understanding-statistical-tests.html#cb81-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_text</span>(<span class="fu">aes</span>(<span class="at">x=</span><span class="fl">0.05</span>, <span class="at">y=</span><span class="dv">0</span>), <span class="at">label=</span><span class="st">&quot;Or does the difference</span><span class="sc">\n</span><span class="st">between treatments explain</span><span class="sc">\n</span><span class="st">more of the variance?&quot;</span>, </span>
<span id="cb81-8"><a href="understanding-statistical-tests.html#cb81-8" aria-hidden="true" tabindex="-1"></a>            <span class="at">hjust=</span><span class="dv">0</span>, <span class="at">vjust=</span><span class="dv">1</span>, <span class="at">size=</span><span class="dv">5</span>) </span>
<span id="cb81-9"><a href="understanding-statistical-tests.html#cb81-9" aria-hidden="true" tabindex="-1"></a>  </span>
<span id="cb81-10"><a href="understanding-statistical-tests.html#cb81-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-11"><a href="understanding-statistical-tests.html#cb81-11" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.locator</span>(<span class="at">unit=</span><span class="st">&quot;native&quot;</span>) </span>
<span id="cb81-12"><a href="understanding-statistical-tests.html#cb81-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-13"><a href="understanding-statistical-tests.html#cb81-13" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.brackets</span>(<span class="dv">95</span>, <span class="dv">200</span>, <span class="dv">95</span>, <span class="dv">370</span>, <span class="at">h=</span><span class="fl">0.05</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span>
<span id="cb81-14"><a href="understanding-statistical-tests.html#cb81-14" aria-hidden="true" tabindex="-1"></a><span class="fu">grid.brackets</span>(<span class="dv">370</span>, <span class="dv">100</span>, <span class="dv">370</span>, <span class="dv">285</span>, <span class="at">h=</span><span class="fl">0.05</span>, <span class="at">lwd=</span><span class="dv">2</span>, <span class="at">col=</span><span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="data-science-for-agricultural-professionals_files/figure-html/unnamed-chunk-75-1.png" width="672" /></p>
<p>The purpose of a trial is to measure both types of effects and render a verdict. Which is hypotheses are important, as we will now see.</p>
</div>
</div>
<div id="hypotheses" class="section level2" number="5.3">
<h2><span class="header-section-number">5.3</span> Hypotheses</h2>
<p>Before we design any experiment, however, we have to define our research question. In the case of a side-by-side trial, the question is generally: “Is one treatments better than the other? This question then needs to be translated into hypotheses.</p>
<p>Outside of statistics, a hypothesis is often described as “an educated guess.” Experiments are designed, however, to test two or more hypotheses. We may casually describe a side-by-side trial as comparing two treatments, but the data are formally used as evidence to test two, opposing hypotheses:</p>
<ul>
<li>Ho: The difference between the two treatments is zero.</li>
<li>Ha: The difference between the two treatments is not zero.</li>
</ul>
<p>The first hypothesis, Ho, is called the <em>null hypothesis</em>. The second hypothesis, Ha, is the <em>alternative hypothesis</em>. Typically, we tend to focus our effort on gathering enough evidence to support the alternative hypothesis: after all this work, we typically want to see a treatment difference! But we need to remember the null hypothesis may also be supported.</p>
<p>This process, like the linear model ahead, probably seems overly-formal at first. But like the linear model, it helps us to understand what statistics really tell us. We cannot prove either of these hypotheses. The world is full of one-off exceptions that will prevent either hypothesis from being universal truths. Our science is about comparing the evidence for each hypothesis, and selecting the hypothesis that is probable enough to meet our standards.</p>
<p>To illustrate this, look no further than the t-test we used in the last unit:</p>
<p><span class="math display">\[ t = \frac{\bar{x}-\mu}{SED} \]</span></p>
<p>Recall that <span class="math inline">\(\bar{x}\)</span> was our treatment difference, <span class="math inline">\(\mu\)</span> was the hypothesized treatment difference (zero), and <span class="math inline">\(SED\)</span> was the standard error of the difference. The numerator is our treatment effect on plot yield. The denominator quantifes the random effects on plot yield. As this ratio increases, so does t. As t increases, the probability that the true population difference is zero decreases.</p>
<p>Another nuance of hypotheses is this, especially when it comes to the alternative hypothesis. If the evidence fails to support the alternative hypothesis, that does not mean it is wrong. The fixed (treatment) effect we observed was real. But the random effect was so great we could not rule out the differences we observed were the result of chance.</p>
<p>Simply put, our confidence interval was too big to rule out the true difference between treatments was actually zero. There was too much variation among plots. In a trial with a lower standard error of the difference, our t-value would have been greater, and the probability that the true difference between treatments was zero would be lesser.</p>
<p>Statistics is not about finding the truth. It is about quantifying the probability an observed difference is the result of chance. Lower probabilities suggest less chance in our observations, and the greater likelihood this difference will be observed if the trial is repeated by someone else, in a laboratory, or in a production field.</p>
</div>
<div id="p-value" class="section level2" number="5.4">
<h2><span class="header-section-number">5.4</span> P-Value</h2>
<p>The P-Value is always a source of confusion in statistics. What does it mean? What is so magical about the 0.05, or 5%, cutoff for declaring populations different? Even if you think you’ve mastered the P_value concept already, let’s review it one more time.</p>
<p>The P-value, as applied to a distribution, is the probability of obseverving a value with a given (or greater) difference from the population mean. For example, if we have a t-distribution with a mean of 0 and a standard error of 1, the probability we will, the probability we will observe a value 2.3 standard errors away than the mean, given a population size of 4, is 0.047, or 4.7%.</p>
<div class="sourceCode" id="cb82"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb82-1"><a href="understanding-statistical-tests.html#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fastGraph)</span>
<span id="cb82-2"><a href="understanding-statistical-tests.html#cb82-2" aria-hidden="true" tabindex="-1"></a><span class="fu">shadeDist</span>(<span class="at">xshade=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">2.3</span>, <span class="fl">2.3</span>), <span class="st">&quot;dt&quot;</span>, <span class="at">parm2 =</span> <span class="dv">9</span>, <span class="at">lower.tail =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="data-science-for-agricultural-professionals_files/figure-html/unnamed-chunk-76-1.png" width="672" /></p>
<p>What does a P-value of 0.047 mean? It means the probability of us measuring this value, by dumb luck, when the true population mean is 0, is about 4.7%. Put another way, given the standard error we observed, if the true population mean was zero, we would observe a value equal to or more than 2.3 units away from the mean in less than 5 out of 100 trials.</p>
<p>If this concept sounds the same as that described for a confidence interval, that’s because it is the same principle. If we constructed a 95% confidence interval around the sample mean of 2.3, we would see it excludes zero.</p>
<p>Knowing this, we have three options. We can conclude, for now, that the population mean really was zero and we were just very lucky (or unlucky) in our sampling.</p>
<p>We could also repeat the trial multiple times, to see what other values occur. If this is a field trial, that will incur additional research expenses. Even worse, it means delaying a recommendation for several seasons.</p>
<p>Our final option would be to conclude that our population mean is probably <em>not</em> zero. If the probability of observing a sample mean 2.3 or more units away from the mean, when the true population mean is zero, is 4.7% or less, then we can also say that the probability that the population mean has a value of zero or less, given our sample mean of 2.3, is 4.7% or less. Given this knowledge, we may conclude the true population mean is different from zero.</p>
<p>This is the power – and beauty! – of statistics. By properly designing an experiment (with sufficient replication and randomization), we can estimate the variability of individuals within a population. We can then use these estimates to test the probability of a hypothetical population mean, given the variability in our sample. And from that, we decide whether one population (which, for example, may have received a new product) is different from the other (which was untreated).</p>
</div>
<div id="the-p-value-and-errors" class="section level2" number="5.5">
<h2><span class="header-section-number">5.5</span> The P-Value and Errors</h2>
<p>There are two kinds of P-value: the P-Value we measure, and the maximum P-Value we will accept before determinng an observed difference between populations is insignificant. This maximum P-Value is referred to as <em>alpha</em> (<span class="math inline">\(\alpha\)</span>). You have probably seen statistical summaries that included whether treatments were “different at the <span class="math inline">\(P \le 0.05\)</span> level. In this case, the <span class="math inline">\(\alpha\)</span> is 0.05, or 5%.</p>
<p>Before we discuss why an alpha of 0.05 or 5% is so often used for statistical tests, we need to understand how it relates to the likelihood we will reach the correct inference when comparing populations. You see, once we have gathered our data, calculated the variance in those populations (or, in the case of the paired t-test, the variance in their differences), and run our test(s), we will conclude either that the two populations are the same, or that they are different.</p>
<p>Either conclusion may be right. Or it may be wrong. And since we rarely measure entire populations, we never know their exact population means. We work with probabilities. In the above example, there was a 4.7% chance we could observe a sample mean 2.3 units from a true population of zero. That means there is a 95.3 % (100 - 4.7) chance we would not see that value by chance. But there is still a chance. In other words, there is still a chance we could conclude the population mean is not zero, when in fact it is.</p>
<p>When we infer the mean of one population is significantly different from another (whether the second mean be measured or hypothesized), when in fact the two population means are equal, we commit a <em>Type I Error</em>. One example would be concluding the yield of one population, having received additional fertilizer, yielded more than an unfertilized population, when in fact their yields were equal. Another example would be concluding there is a difference in the percent of corn rejected from two populations, each treated with a different insecticide.</p>
<p>The P-value is the probability of making that Type I Error: of observing a sample mean so improbable enough that it leads us to conclude two populations are different, when for all purposes they are the same. If we are worried that recommending a product to a grower that does not increase yield will cost us their business, then we are worried about making a Type I Error. Outside of agriculture, if we are worried about releasing a treatment for COVID-19 that does not work and will leave users unprotected, we are worried about a Type I Error.</p>
<p>If we are really, really worried about wrongly inferring a difference between populations, we might use an even lower P-value. We might use P=0.01, which means we will not infer two treatments are different unless the mean difference we observe has less than a 1% probability of being observed by chance. This might be the case if the product we recommend to a grower is not $10 per acre, but $30. If our COVID treatment is very expensive or has serious side effects, we might insist on an even lower alpha, say P=0.001, or 0.1%.</p>
<p>So why not always use an alpha of 0.01 or 0.001 to infer whether two populations are different?</p>
<p>There is a second error we can make in the inferences from our research: we can conclude two populations are not different, when in fact they are. In this case, we observed, by chance, a sample mean from one population that was very close to the mean (hypothesized or measured) of another population, when in fact the two population means are different.</p>
<p>For example, a plant breeder might conclude a there performance of a new hybrid is similar to an existing hybrid, and fail to advance it for further testing. An agronomist might erroneously conclude there is no difference in plants treated with one of two micronnutrient fertilizers, and fail to recommend the superior one to a grower.</p>
<p>Even more dangerously, a health researcher might conclude there is no difference in the incidence of strokes between a population that receives a new medication and an untreated population, and erroneously conclude a that mdeciation is safe.</p>
<p>Thus, there is a tradeoff betwteen Type I and Type II errors. By reducing the alpha used as critierial to judge whether an one value is significantly different from another, we reduce the likelihood of a Type I error, but increase the likelihood of a Type II error.</p>
<p>In agronomic research, we conventionally use an alpha of 0.05. I cannot explain why we use that particular alpha, other than to suggest it provides an acceptable balance between the risks of Type I and Type II errors for our purposes. It is a value that assures most of the time we will only adopt new practices that very likely to increase biomass or quality, while preventing us wrongly rejecting other practices. In my research, I might use an alpha of 0.05 in comparing hybrids for commercial use. But I might use an alpha of 0.10 or 0.15 if I was doing more basic work in weed ecology where I was testing a very general hypothesis to explain their behavior.</p>
<p>To make things simple, wew will use an alpha of 0.05 for tests in this course, unless states otherwise.</p>
</div>
<div id="one-sided-vs-two-sided-hypotheses" class="section level2" number="5.6">
<h2><span class="header-section-number">5.6</span> One-Sided vs Two-Sided Hypotheses</h2>
<p>So far, we have treated our hypotheses as:</p>
<p>Ho: there is no difference between two populations, each treated with a different input or practice
Ha: there is a difference between two populations, each treated with a different input or practice</p>
<p>We could casually refer to these as “no difference” and “any difference”. But often in side-by-side trials, we have an intuitive sense (or hope) that one population will be “better” than another. If we are the yield of the two populations, one planted with an older hybrid and the other with a newer hybrid, we may be trying to determine whether the new hybrid is likely to yield more. If we comparing the number of infected plants in populations treated with different fungicides, we may hope the population that receives the new technology will have fewer diseased plants that the population that receives the older technology..</p>
<p>Is this bias? Yes. Is it wrong? I would argue no. The whole purpose of product development, in which I work, is to identify better products. Better hybrids, better micronutrients, better plant growth regulators. If we were equally satisfied whether a new product performed significantly better or significantly worse than an older product – well, in that case, I’d better look into teaching another section of this course.</p>
<p>It is okay to have this kind of bias, so long as we keep our research honest. Proper experimental design, including replication and randomization of plots in the field, or pots in the greenhouse, will go a long way towards that honest. So will selection of a P-value that acceptably minimizes Type I errors, so that we don’t advance a new product which isn’t highly likely to perform better in future trials, or in the grower’s field.</p>
<p>When we have this kind of bias, or interest, however, it also changes our hypotheses. Our null hypothesis is that the population treated with the new product will not perform better than the population treated with the old product. Our alternative hypothesis is the population treated with the new product will perform better.</p>
<p>If we are comparing yield in corn populations treated with a new fungicide, our hypotheses will be:</p>
<ul>
<li>Ho: The yield of the population that receives the new fungicide will be equal too – <em>or lesser</em> – than the yield of the population that receives the old fungicide.</li>
<li>Ha: The yield of the population that receives the new fungicide will be <em>greater</em> than the yield of the population that receives the old fungicide.</li>
</ul>
<p>The reason these are called one-sided hypotheses is because we are only interersted in one-side of the normal distribution. In the two-sided hypotheses we have worked with, we would only care if the yield of the two populations (one receiving the old fungicide, the other receiving the new fungicide) were different. To visualize this</p>
<div class="sourceCode" id="cb83"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb83-1"><a href="understanding-statistical-tests.html#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fastGraph)</span>
<span id="cb83-2"><a href="understanding-statistical-tests.html#cb83-2" aria-hidden="true" tabindex="-1"></a>alpha_05_2side <span class="ot">=</span> <span class="fu">qt</span>(<span class="fl">0.975</span>, <span class="dv">4</span>)</span>
<span id="cb83-3"><a href="understanding-statistical-tests.html#cb83-3" aria-hidden="true" tabindex="-1"></a><span class="fu">shadeDist</span>(<span class="at">xshade=</span><span class="fu">c</span>(<span class="sc">-</span>alpha_05_2side, alpha_05_2side), <span class="st">&quot;dt&quot;</span>, <span class="at">parm2 =</span> <span class="dv">4</span>, <span class="at">lower.tail =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="data-science-for-agricultural-professionals_files/figure-html/unnamed-chunk-77-1.png" width="672" /></p>
<p>If either <span class="math inline">\(t\le-2.78\)</span> or <span class="math inline">\(t\ge-2.78\)</span> (either of the red areas above), we declare the two populations different. In other words, the observed t-value can occur in either of the two tails and be significant. Accordingly, we refer to this as a two-tailed test.</p>
<p>In testing a one-sided hypothesis, we only care if the difference between the population that received the new fungicide and the population that received the old fungicide (ie new fungicide - old fungicide) has a t-value of 1.98 or greater. We would visualize this as:</p>
<div class="sourceCode" id="cb84"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb84-1"><a href="understanding-statistical-tests.html#cb84-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fastGraph)</span>
<span id="cb84-2"><a href="understanding-statistical-tests.html#cb84-2" aria-hidden="true" tabindex="-1"></a>alpha_05_1side <span class="ot">=</span> <span class="fu">qt</span>(<span class="fl">0.975</span>, <span class="dv">4</span>)</span>
<span id="cb84-3"><a href="understanding-statistical-tests.html#cb84-3" aria-hidden="true" tabindex="-1"></a><span class="fu">shadeDist</span>(<span class="at">xshade=</span>alpha_05_1side, <span class="st">&quot;dt&quot;</span>, <span class="at">parm2 =</span> <span class="dv">4</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="data-science-for-agricultural-professionals_files/figure-html/unnamed-chunk-78-1.png" width="672" /></p>
<p>Only if the measured t-value falls in the upper tail will the population that receives the new fungicide be considered significantly better than the population that received the old fungicide. We therefor – you guessed it! – refer to this test as a one-tailed test.</p>
<p>In using a one-tailed test, however, we need to use a different t-value to achieve our alpha (maximum p-value for significance). If you look at the plot, only 2.5% of the distribution is in the upper tail. If we leave this as it is, we will only conclude the populations are different is their P-value is equal to or less than 2.5%. Reducing our P-value from 5% to 2.5% will, indeed, reduce our probability of Type I errors. But it will increase our likelihood of Type II errors.</p>
<p>If we are going to conduct a one-tailed test with an alpha of 0.05, we need to adjust the percentage of the distribution in the upper tail to 5% of the distribution:</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="understanding-statistical-tests.html#cb85-1" aria-hidden="true" tabindex="-1"></a>alpha_05_1side <span class="ot">=</span> <span class="fu">qt</span>(<span class="fl">0.95</span>, <span class="dv">4</span>)</span>
<span id="cb85-2"><a href="understanding-statistical-tests.html#cb85-2" aria-hidden="true" tabindex="-1"></a><span class="fu">shadeDist</span>(<span class="at">xshade=</span>alpha_05_1side, <span class="st">&quot;dt&quot;</span>, <span class="at">parm2 =</span> <span class="dv">4</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<p><img src="data-science-for-agricultural-professionals_files/figure-html/unnamed-chunk-79-1.png" width="672" /></p>
<p>The implication is that the minimum difference between populations to be significant at an alpha=0.05 is lesser than for a two-tailed test.</p>
<p>A common first response to the one-tailed test is: “Isn’t that cheating? Aren’t we just switching to a one-tailed test so we can nudge our difference passed the goal line for significance”? And, indeed, if you switch to a one-tailed test for that reason alone, it is cheating. That is why it is important we declare our hypotheses before we begin our trial. If we are going to run a one-tailed test, it needs to be based on a one-sided hypothesis that declares, from the beginning, we are only testing the difference in one direction, either because we have intuition that the difference will be one-sided, or we have a practical reason for only being interested in a positive or negative difference between populations.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="two-treatment-comparisons.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="multiple-treatment-trials.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": "https://github.com/USERNAME/REPO/edit/BRANCH/05-Understanding-Statistical-Tests.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["data-science-for-agricultural-professionals.pdf", "data-science-for-agricultural-professionals.epub"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
